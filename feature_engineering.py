"""
STEP 2: Feature Engineering
============================
AmaÃ§:
- Son bakÄ±m tarihi hesaplama (Checklist/Ä°ÅŸ Emri verilerinden)
- ArÄ±za geÃ§miÅŸi agregasyonu (12ay, 6ay, 3ay)
- Proxy yÃ¼klenme deÄŸiÅŸkenleri (baÄŸlÄ± mÃ¼ÅŸteri, fider yoÄŸunluÄŸu)
- Marka/Model extraction
- CoÄŸrafi faktÃ¶rler (kentsel/kÄ±rsal)
- Temporal features (mevsim, tatil, hava durumu proxy)
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import warnings
import os
warnings.filterwarnings('ignore')

# ============================================================================
# CONFIGURATION
# ============================================================================
INPUT_FILE = 'outputs/step1_processed_data.xlsx'
OUTPUT_DIR = 'outputs/'
REFERENCE_DATE = datetime.now()

print("=" * 80)
print("STEP 2: FEATURE ENGINEERING")
print("=" * 80)
print(f"Reference Date: {REFERENCE_DATE.strftime('%Y-%m-%d')}\n")

# ============================================================================
# 1. LOAD PROCESSED DATA FROM STEP 1
# ============================================================================
print("[1/8] Loading processed data from STEP 1...")
try:
    df = pd.read_excel(INPUT_FILE, engine='openpyxl')
    print(f"âœ“ Data loaded: {df.shape[0]:,} rows x {df.shape[1]} columns\n")
except Exception as e:
    print(f"âœ— Error: {e}")
    print("Trying CSV format...")
    df = pd.read_csv(INPUT_FILE.replace('.xlsx', '.csv'))
    print(f"âœ“ Data loaded: {df.shape[0]:,} rows x {df.shape[1]} columns\n")

# Parse dates if needed
if df['ArÄ±za_Tarihi'].dtype == 'object':
    df['ArÄ±za_Tarihi'] = pd.to_datetime(df['ArÄ±za_Tarihi'])
if 'Tamamlanma_Tarihi' in df.columns:
    df['Tamamlanma_Tarihi_parsed'] = pd.to_datetime(df['Tamamlanma_Tarihi'], errors='coerce')

# ============================================================================
# 2. ARIZA GEÃ‡MÄ°ÅžÄ° FEATURES (Fault History)
# ============================================================================
print("[2/8] Calculating Fault History Features...")

# Sort by equipment and date
df_sorted = df.sort_values(['Ekipman Kodu', 'ArÄ±za_Tarihi'])

# Calculate fault counts for each equipment
fault_history = []

for idx, row in df_sorted.iterrows():
    ekipman = row['Ekipman Kodu']
    ariza_tarihi = row['ArÄ±za_Tarihi']
    
    # Get all previous faults for this equipment
    prev_faults = df_sorted[
        (df_sorted['Ekipman Kodu'] == ekipman) & 
        (df_sorted['ArÄ±za_Tarihi'] < ariza_tarihi)
    ]
    
    # Count faults in different time windows
    date_12m = ariza_tarihi - timedelta(days=365)
    date_6m = ariza_tarihi - timedelta(days=182)
    date_3m = ariza_tarihi - timedelta(days=91)
    
    faults_12m = len(prev_faults[prev_faults['ArÄ±za_Tarihi'] >= date_12m])
    faults_6m = len(prev_faults[prev_faults['ArÄ±za_Tarihi'] >= date_6m])
    faults_3m = len(prev_faults[prev_faults['ArÄ±za_Tarihi'] >= date_3m])
    faults_total = len(prev_faults)
    
    # Calculate days since last fault
    if len(prev_faults) > 0:
        last_fault_date = prev_faults['ArÄ±za_Tarihi'].max()
        days_since_last = (ariza_tarihi - last_fault_date).days
    else:
        days_since_last = None
    
    # Calculate MTBF (Mean Time Between Failures)
    if faults_total >= 2:
        time_span = (ariza_tarihi - prev_faults['ArÄ±za_Tarihi'].min()).days
        mtbf = time_span / faults_total
    else:
        mtbf = None
    
    fault_history.append({
        'ArÄ±za_SayÄ±sÄ±_12ay': faults_12m,
        'ArÄ±za_SayÄ±sÄ±_6ay': faults_6m,
        'ArÄ±za_SayÄ±sÄ±_3ay': faults_3m,
        'Toplam_ArÄ±za_SayÄ±sÄ±': faults_total,
        'Son_ArÄ±zadan_GÃ¼n': days_since_last,
        'MTBF_GÃ¼n': mtbf,
        'Tekrarlayan_ArÄ±za_Flag': 1 if faults_3m >= 2 else 0
    })

# Add to dataframe
fault_df = pd.DataFrame(fault_history)
df = pd.concat([df.reset_index(drop=True), fault_df], axis=1)

print(f"âœ“ Fault history features created:")
print(f"  - ArÄ±za_SayÄ±sÄ±_12ay: Mean = {df['ArÄ±za_SayÄ±sÄ±_12ay'].mean():.2f}")
print(f"  - ArÄ±za_SayÄ±sÄ±_6ay: Mean = {df['ArÄ±za_SayÄ±sÄ±_6ay'].mean():.2f}")
print(f"  - ArÄ±za_SayÄ±sÄ±_3ay: Mean = {df['ArÄ±za_SayÄ±sÄ±_3ay'].mean():.2f}")
print(f"  - Tekrarlayan ArÄ±za: {df['Tekrarlayan_ArÄ±za_Flag'].sum():,} cases ({df['Tekrarlayan_ArÄ±za_Flag'].sum()/len(df)*100:.1f}%)\n")

# ============================================================================
# 3. SON BAKIM TARÄ°HÄ° (Last Maintenance Date)
# ============================================================================
print("[3/8] Calculating Last Maintenance Date...")

# Group by equipment and find last maintenance-related work order
# Looking for work orders with maintenance keywords
maintenance_keywords = ['BakÄ±m', 'bakÄ±m', 'BAKIM', 'Periyodik', 'Ã–nleyici', 'Koruyucu']

if 'Ä°ÅŸ Emri Tipi' in df.columns:
    # Create maintenance flag
    df['Is_Maintenance'] = df['Ä°ÅŸ Emri Tipi'].str.contains('|'.join(maintenance_keywords), na=False, case=False)
    
    # For each row, find last maintenance before this fault
    last_maintenance = []
    
    for idx, row in df.iterrows():
        ekipman = row['Ekipman Kodu']
        ariza_tarihi = row['ArÄ±za_Tarihi']
        
        # Find last maintenance for this equipment before fault
        prev_maintenance = df[
            (df['Ekipman Kodu'] == ekipman) & 
            (df['ArÄ±za_Tarihi'] < ariza_tarihi) &
            (df['Is_Maintenance'] == True)
        ]
        
        if len(prev_maintenance) > 0:
            last_maint_date = prev_maintenance['ArÄ±za_Tarihi'].max()
            days_since_maint = (ariza_tarihi - last_maint_date).days
        else:
            days_since_maint = None
        
        last_maintenance.append(days_since_maint)
    
    df['Son_BakÄ±m_GÃ¼n_SayÄ±sÄ±'] = last_maintenance
    
    valid_maint = df['Son_BakÄ±m_GÃ¼n_SayÄ±sÄ±'].notna().sum()
    print(f"âœ“ Last maintenance calculated for {valid_maint:,} records ({valid_maint/len(df)*100:.1f}%)")
    if valid_maint > 0:
        print(f"  - Mean days since maintenance: {df['Son_BakÄ±m_GÃ¼n_SayÄ±sÄ±'].mean():.1f}")
        print(f"  - Median: {df['Son_BakÄ±m_GÃ¼n_SayÄ±sÄ±'].median():.1f}\n")
else:
    df['Son_BakÄ±m_GÃ¼n_SayÄ±sÄ±'] = None
    print("âš  Ä°ÅŸ Emri Tipi column not found, skipping maintenance calculation\n")

# ============================================================================
# 4. PROXY YÃœKLENME DEÄžÄ°ÅžKENLERÄ° (Customer-based Loading Proxies)
# ============================================================================
print("[4/8] Creating Customer-based Loading Variables...")

# Customer count columns (already in data!)
customer_columns = {
    'total customer count': 'Toplam_MÃ¼ÅŸteri_SayÄ±sÄ±',
    'urban mv': 'Kentsel_OG_MÃ¼ÅŸteri',
    'urban lv': 'Kentsel_AG_MÃ¼ÅŸteri',
    'suburban mv': 'KentaltÄ±_OG_MÃ¼ÅŸteri',
    'suburban lv': 'KentaltÄ±_AG_MÃ¼ÅŸteri',
    'rural mv': 'KÄ±rsal_OG_MÃ¼ÅŸteri',
    'rural lv': 'KÄ±rsal_AG_MÃ¼ÅŸteri'
}

for orig_col, new_col in customer_columns.items():
    if orig_col in df.columns:
        df[new_col] = pd.to_numeric(df[orig_col], errors='coerce').fillna(0)
    else:
        df[new_col] = 0
        print(f"  âš ï¸ {orig_col} not found, using 0")

# Calculate customer type ratios
df['Kentsel_MÃ¼ÅŸteri_OranÄ±'] = (df['Kentsel_OG_MÃ¼ÅŸteri'] + df['Kentsel_AG_MÃ¼ÅŸteri']) / (df['Toplam_MÃ¼ÅŸteri_SayÄ±sÄ±'] + 1)
df['KÄ±rsal_MÃ¼ÅŸteri_OranÄ±'] = (df['KÄ±rsal_OG_MÃ¼ÅŸteri'] + df['KÄ±rsal_AG_MÃ¼ÅŸteri']) / (df['Toplam_MÃ¼ÅŸteri_SayÄ±sÄ±'] + 1)
df['OG_MÃ¼ÅŸteri_OranÄ±'] = (df['Kentsel_OG_MÃ¼ÅŸteri'] + df['KentaltÄ±_OG_MÃ¼ÅŸteri'] + df['KÄ±rsal_OG_MÃ¼ÅŸteri']) / (df['Toplam_MÃ¼ÅŸteri_SayÄ±sÄ±'] + 1)

print(f"âœ“ Customer count features created:")
print(f"  - Total customers: Mean = {df['Toplam_MÃ¼ÅŸteri_SayÄ±sÄ±'].mean():.1f}, Max = {df['Toplam_MÃ¼ÅŸteri_SayÄ±sÄ±'].max():.0f}")
print(f"  - Urban ratio: Mean = {df['Kentsel_MÃ¼ÅŸteri_OranÄ±'].mean():.2%}")
print(f"  - Rural ratio: Mean = {df['KÄ±rsal_MÃ¼ÅŸteri_OranÄ±'].mean():.2%}")

# Calculate fider density (faults per fider)
if 'Fider ID' in df.columns:
    fider_stats = df.groupby('Fider ID').agg({
        'id': 'count',  # Number of faults
        'Toplam_MÃ¼ÅŸteri_SayÄ±sÄ±': 'sum'  # Total customers
    }).rename(columns={'id': 'Fider_ArÄ±za_SayÄ±sÄ±', 'Toplam_MÃ¼ÅŸteri_SayÄ±sÄ±': 'Fider_Toplam_MÃ¼ÅŸteri'})
    
    df = df.merge(fider_stats, left_on='Fider ID', right_index=True, how='left', suffixes=('', '_fider'))
    
    print(f"âœ“ Fider-based features created:")
    print(f"  - Unique fiders: {df['Fider ID'].nunique()}")
    print(f"  - Fider mean customers: {df['Fider_Toplam_MÃ¼ÅŸteri'].mean():.1f}")
else:
    print("âš ï¸ Fider ID not found")

# Equipment load proxy (based on fault frequency and customer count)
df['Ekipman_YoÄŸunluk_Skoru'] = df['ArÄ±za_SayÄ±sÄ±_12ay'] / (df['Ekipman_YaÅŸÄ±_YÄ±l'] + 1)
df['MÃ¼ÅŸteri_BaÅŸÄ±na_ArÄ±za'] = df['ArÄ±za_SayÄ±sÄ±_12ay'] / (df['Toplam_MÃ¼ÅŸteri_SayÄ±sÄ±'] + 1)

print(f"  - Ekipman_YoÄŸunluk_Skoru: Mean = {df['Ekipman_YoÄŸunluk_Skoru'].mean():.3f}")
print(f"  - MÃ¼ÅŸteri_BaÅŸÄ±na_ArÄ±za: Mean = {df['MÃ¼ÅŸteri_BaÅŸÄ±na_ArÄ±za'].mean():.4f}\n")

# ============================================================================
# 5. MARKA & MODEL EXTRACTION
# ============================================================================
print("[5/8] Extracting Equipment Brand & Model...")

def extract_brand_model(equipment_desc):
    """Extract brand and model from equipment description"""
    if pd.isna(equipment_desc):
        return None, None, None
    
    desc = str(equipment_desc).upper()
    
    # Common brands
    brands = ['SIEMENS', 'ABB', 'SCHNEIDER', 'AREVA', 'EATON', 'BEST', 'ORMAZABAL', 
              'TAMINI', 'TRAFOMAK', 'Ã‡ESAN', 'ERMAK', 'AKSA']
    
    brand = None
    for b in brands:
        if b in desc:
            brand = b
            break
    
    # Extract kVA rating
    import re
    kva_match = re.search(r'(\d+)\s*KVA', desc)
    kva_rating = kva_match.group(1) if kva_match else None
    
    # Extract voltage
    voltage_match = re.search(r'(\d+\.?\d*)/(\d+\.?\d*)\s*KV', desc)
    voltage = f"{voltage_match.group(1)}/{voltage_match.group(2)}" if voltage_match else None
    
    return brand, kva_rating, voltage

# Apply extraction
if 'Ekipman TanÄ±mÄ±' in df.columns:
    extraction = df['Ekipman TanÄ±mÄ±'].apply(extract_brand_model)
    df['Marka'] = extraction.apply(lambda x: x[0])
    df['kVA_Rating'] = extraction.apply(lambda x: x[1])
    df['Voltaj'] = extraction.apply(lambda x: x[2])
    
    brand_count = df['Marka'].notna().sum()
    print(f"âœ“ Brand extraction: {brand_count:,} records ({brand_count/len(df)*100:.1f}%)")
    print(f"  - Unique brands: {df['Marka'].nunique()}")
    if df['Marka'].notna().sum() > 0:
        print(f"  - Top brands: {df['Marka'].value_counts().head(3).to_dict()}")
else:
    print("âš  Ekipman TanÄ±mÄ± not found\n")

print()

# ============================================================================
# 6. COÄžRAFÄ° FAKTÃ–RLER (Geographic Factors)
# ============================================================================
print("[6/8] Creating Geographic Features...")

# Urban vs Rural classification
urban_districts = [
    'ALAÅžEHÄ°R', 'SALIHLI', 'SALÄ°HLÄ°',  # BÃ¼yÃ¼k/kÃ¼Ã§Ã¼k harf varyasyonlarÄ±
    'GÃ–RDES', 'GORDES',
    'AlaÅŸehir', 'Salihli', 'GÃ¶rdes'  # Title case
]
if 'Ä°lÃ§e' in df.columns:
    df['BÃ¶lge_Tipi'] = df['Ä°lÃ§e'].apply(
        lambda x: 'Kentsel' if str(x).upper() in urban_districts else 'KÄ±rsal'
    )
    
    print(f"âœ“ Geographic classification:")
    print(f"  - Kentsel: {(df['BÃ¶lge_Tipi'] == 'Kentsel').sum():,} ({(df['BÃ¶lge_Tipi'] == 'Kentsel').sum()/len(df)*100:.1f}%)")
    print(f"  - KÄ±rsal: {(df['BÃ¶lge_Tipi'] == 'KÄ±rsal').sum():,} ({(df['BÃ¶lge_Tipi'] == 'KÄ±rsal').sum()/len(df)*100:.1f}%)\n")

# Coordinate-based features (if available)
if 'KOORDINAT_X' in df.columns and 'KOORDINAT_Y' in df.columns:
    # Create grid zones for spatial analysis
    df['Coord_Zone'] = (
        df['KOORDINAT_X'].astype(str).str[:4] + '_' + 
        df['KOORDINAT_Y'].astype(str).str[:4]
    )
    print(f"  - Coordinate zones created: {df['Coord_Zone'].nunique()} unique zones\n")

# ============================================================================
# 7. TEMPORAL FEATURES
# ============================================================================
print("[7/8] Creating Temporal Features...")

df['YÄ±l'] = df['ArÄ±za_Tarihi'].dt.year
df['Ay'] = df['ArÄ±za_Tarihi'].dt.month
df['GÃ¼n'] = df['ArÄ±za_Tarihi'].dt.day
df['HaftanÄ±n_GÃ¼nÃ¼'] = df['ArÄ±za_Tarihi'].dt.dayofweek  # 0=Monday, 6=Sunday
df['Hafta_Ä°Ã§i'] = df['HaftanÄ±n_GÃ¼nÃ¼'].apply(lambda x: 1 if x < 5 else 0)

# Season
def get_season(month):
    if month in [12, 1, 2]:
        return 'KÄ±ÅŸ'
    elif month in [3, 4, 5]:
        return 'Ä°lkbahar'
    elif month in [6, 7, 8]:
        return 'Yaz'
    else:
        return 'Sonbahar'

df['Mevsim'] = df['Ay'].apply(get_season)

# Hour (if time available)
if df['ArÄ±za_Tarihi'].dt.hour.notna().sum() > 0:
    df['Saat'] = df['ArÄ±za_Tarihi'].dt.hour
    df['Gece_GÃ¼ndÃ¼z'] = df['Saat'].apply(lambda x: 'GÃ¼ndÃ¼z' if 6 <= x < 18 else 'Gece')
    print(f"âœ“ Temporal features created (including hour)")
else:
    print(f"âœ“ Temporal features created (date only)")

print(f"  - Year range: {df['YÄ±l'].min()} - {df['YÄ±l'].max()}")
print(f"  - Mevsim distribution:")
for season, count in df['Mevsim'].value_counts().items():
    print(f"    {season}: {count:,} ({count/len(df)*100:.1f}%)\n")

# ============================================================================
# 8. SUMMARY STATISTICS
# ============================================================================
print("=" * 80)
print("[8/8] FEATURE ENGINEERING SUMMARY")
print("=" * 80)

new_features = [
    'ArÄ±za_SayÄ±sÄ±_12ay', 'ArÄ±za_SayÄ±sÄ±_6ay', 'ArÄ±za_SayÄ±sÄ±_3ay',
    'Son_ArÄ±zadan_GÃ¼n', 'MTBF_GÃ¼n', 'Tekrarlayan_ArÄ±za_Flag',
    'Son_BakÄ±m_GÃ¼n_SayÄ±sÄ±', 
    'Toplam_MÃ¼ÅŸteri_SayÄ±sÄ±', 'Kentsel_MÃ¼ÅŸteri_OranÄ±', 'KÄ±rsal_MÃ¼ÅŸteri_OranÄ±',
    'Ekipman_YoÄŸunluk_Skoru', 'MÃ¼ÅŸteri_BaÅŸÄ±na_ArÄ±za',
    'Marka', 'kVA_Rating', 'BÃ¶lge_Tipi',
    'Mevsim', 'Hafta_Ä°Ã§i', 'YÄ±l', 'Ay'
]

print("\nðŸ“Š NEW FEATURES CREATED:")
for i, feature in enumerate(new_features, 1):
    if feature in df.columns:
        non_null = df[feature].notna().sum()
        print(f"  {i:2d}. {feature:30s}: {non_null:6,} non-null ({non_null/len(df)*100:5.1f}%)")

print("\nðŸ“ˆ KEY STATISTICS:")
print(f"  Total rows: {len(df):,}")
print(f"  Total features: {len(df.columns)}")
print(f"  New features: {len([f for f in new_features if f in df.columns])}")

print("\nâ­ KESICI EQUIPMENT FOCUS:")
kesici_mask = df['Ekipman SÄ±nÄ±fÄ±'].str.contains('Kesici', na=False, case=False)
kesici_df = df[kesici_mask]
print(f"  Kesici count: {len(kesici_df):,}")
print(f"  Mean faults (12m): {kesici_df['ArÄ±za_SayÄ±sÄ±_12ay'].mean():.2f}")
print(f"  Mean age: {kesici_df['Ekipman_YaÅŸÄ±_YÄ±l'].mean():.1f} years")
print(f"  Repeating faults: {kesici_df['Tekrarlayan_ArÄ±za_Flag'].sum():,}")

# ============================================================================
# 9. SAVE PROCESSED DATA
# ============================================================================
print("\n" + "=" * 80)
print("SAVING PROCESSED DATA")
print("=" * 80)

output_file = OUTPUT_DIR + 'step2_feature_engineered_data.xlsx'
try:
    df.to_excel(output_file, index=False, engine='openpyxl')
    print(f"âœ“ Saved to: {output_file}")
except Exception as e:
    print(f"Warning: Could not save as Excel: {e}")
    output_file = OUTPUT_DIR + 'step2_feature_engineered_data.csv'
    df.to_csv(output_file, index=False, encoding='utf-8-sig')
    print(f"âœ“ Saved to: {output_file}")

# Save feature summary
summary_file = OUTPUT_DIR + 'step2_feature_summary.txt'
with open(summary_file, 'w', encoding='utf-8') as f:
    f.write("=" * 80 + "\n")
    f.write("STEP 2: FEATURE ENGINEERING SUMMARY\n")
    f.write("=" * 80 + "\n\n")
    f.write(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    f.write(f"Total Records: {len(df):,}\n")
    f.write(f"Total Features: {len(df.columns)}\n\n")
    f.write("New Features:\n")
    for feature in new_features:
        if feature in df.columns:
            f.write(f"  - {feature}\n")
    f.write("\nKey Statistics:\n")
    f.write(f"  Mean faults (12m): {df['ArÄ±za_SayÄ±sÄ±_12ay'].mean():.2f}\n")
    f.write(f"  Repeating faults: {df['Tekrarlayan_ArÄ±za_Flag'].sum():,}\n")
    f.write(f"  Kesici equipment: {kesici_mask.sum():,}\n")

print(f"âœ“ Summary saved to: {summary_file}")

print("\n" + "=" * 80)
print("âœ“ STEP 2 COMPLETED SUCCESSFULLY")
print("=" * 80)
print("\nâœ… Ready for STEP 3: Exploratory Data Analysis & Modeling\n")